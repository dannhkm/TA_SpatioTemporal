{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d13bc7ad",
      "metadata": {
        "id": "d13bc7ad"
      },
      "source": [
        "### Tahap 1: Pemuatan Data dan Inisialisasi (File ini dijalankan di google colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "k4Q_kJz8KPSe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Q_kJz8KPSe",
        "outputId": "d0edcf89-1f28-4b46-cc3f-7355431ae03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- Tahap 1: Hubungkan ke Google Drive ---\n",
        "# ==============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1297f4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1297f4d",
        "outputId": "810b8d52-9853-4302-930a-1bdce31e2779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Path Proyek Berhasil Ditemukan: /content/drive/Othercomputers/My Laptop (2)/Git/TA_SpatioTemporal\n",
            "\n",
            "Berhasil memuat train_set.parquet dan test_set.parquet dari Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- Tahap 2: Atur Path, Muat Library & Data ---\n",
        "# ==============================================================================\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# --- Atur BASE_DIR secara manual ---\n",
        "# Path ini sudah dikonfirmasi benar dari percakapan kita sebelumnya\n",
        "BASE_DIR = \"/content/drive/Othercomputers/My Laptop (2)/Git/TA_SpatioTemporal\"\n",
        "\n",
        "# --- Verifikasi Path & Definisikan Sub-folder ---\n",
        "if not os.path.exists(BASE_DIR):\n",
        "    print(f\"❌ GAGAL: Path tidak ditemukan di: {BASE_DIR}\")\n",
        "else:\n",
        "    print(f\"✅ Path Proyek Berhasil Ditemukan: {BASE_DIR}\")\n",
        "    PATH_SPLIT_DATA = os.path.join(BASE_DIR, 'Data', 'split_data')\n",
        "    PATH_PREDICTIONS = os.path.join(BASE_DIR, 'Data', 'predictions')\n",
        "    os.makedirs(PATH_PREDICTIONS, exist_ok=True)\n",
        "\n",
        "    # --- Muat Data ---\n",
        "    try:\n",
        "        train_df = pd.read_parquet(os.path.join(PATH_SPLIT_DATA, 'train_set.parquet'))\n",
        "        test_df = pd.read_parquet(os.path.join(PATH_SPLIT_DATA, 'test_set.parquet'))\n",
        "        print(\"\\nBerhasil memuat train_set.parquet dan test_set.parquet dari Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Gagal memuat data: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12aa188",
      "metadata": {
        "id": "a12aa188"
      },
      "source": [
        "### Tahap 3: Pra-pemrosesan Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb174541",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb174541",
        "outputId": "f7cd932a-12fe-4d5a-fcf2-87c8bfd4d67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitur yang akan digunakan: ['is_kelas', 'is_kantor', 'is_penelitian', 'avg_temp_previous_hour', 'jam', 'hari_minggu', 'hari_bulan', 'minggu_tahun', 'bulan', 'tahun', 'konsumsi_lag_1_jam', 'konsumsi_lag_24_jam']\n",
            "\n",
            "Memproses Data Latih...\n",
            "Memproses Data Uji...\n",
            "\n",
            "Bentuk data latih (X, y): (282555, 24, 12), (282555, 1)\n",
            "Bentuk data uji (X, y): (47541, 24, 12), (47541, 1)\n",
            "\n",
            "Data siap untuk dimasukkan ke model.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- Tahap 3: Pra-pemrosesan Data menjadi Sekuens ---\n",
        "# ==============================================================================\n",
        "if 'train_df' in locals():\n",
        "    # --- Definisikan Fitur dan Target (PENTING!) ---\n",
        "    TARGET = 'konsumsi_energi'\n",
        "    FEATURES = [col for col in train_df.columns if col not in ['timestamp', 'meter_id', TARGET, 'apakah_akhir_pekan', 'apakah_jam_kerja']]\n",
        "    print(\"\\nFitur yang akan digunakan:\", FEATURES)\n",
        "\n",
        "    # --- Konfigurasi LSTM ---\n",
        "    N_PAST = 24 # Jumlah jam masa lalu yang digunakan untuk prediksi\n",
        "    N_FUTURE = 1 # Memprediksi 1 jam ke depan\n",
        "\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "    scalers = {} # Dictionary untuk menyimpan scaler untuk setiap gedung\n",
        "\n",
        "    # --- Proses Data Latih ---\n",
        "    print(\"\\nMemproses Data Latih...\")\n",
        "    for meter_id, group in train_df.groupby('meter_id'):\n",
        "        scaler = MinMaxScaler()\n",
        "        group_scaled = scaler.fit_transform(group[FEATURES + [TARGET]])\n",
        "        scalers[meter_id] = scaler\n",
        "        for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
        "            X_train.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
        "            y_train.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
        "\n",
        "    # --- Proses Data Uji ---\n",
        "    print(\"Memproses Data Uji...\")\n",
        "    test_indices = []\n",
        "    for meter_id, group in test_df.groupby('meter_id'):\n",
        "        if meter_id in scalers:\n",
        "            scaler = scalers[meter_id]\n",
        "            group_scaled = scaler.transform(group[FEATURES + [TARGET]])\n",
        "            for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
        "                X_test.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
        "                y_test.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
        "                test_indices.append(group.index[i + N_FUTURE - 1])\n",
        "\n",
        "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "    print(f\"\\nBentuk data latih (X, y): {X_train.shape}, {y_train.shape}\")\n",
        "    print(f\"Bentuk data uji (X, y): {X_test.shape}, {y_test.shape}\")\n",
        "    print(\"\\nData siap untuk dimasukkan ke model.\")\n",
        "else:\n",
        "    print(\"❌ GAGAL: Variabel 'train_df' tidak ditemukan. Harap jalankan sel sebelumnya terlebih dahulu.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a2dffe",
      "metadata": {
        "id": "02a2dffe"
      },
      "source": [
        "### Tahap 4: Bangun & Latih Model LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0a59b9b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0a59b9b3",
        "outputId": "14fcefb2-97bc-45f0-e7ff-afb54d43a353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Membangun Model LSTM 2-Lapis ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m19,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,161</span> (125.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,161\u001b[0m (125.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,161</span> (125.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,161\u001b[0m (125.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memulai pelatihan model...\n",
            "Epoch 1/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - loss: 0.0120 - val_loss: 0.0048\n",
            "Epoch 2/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0046\n",
            "Epoch 3/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 4/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0040\n",
            "Epoch 5/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 6/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 7/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 8/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 9/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 10/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 11/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 12/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 13/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 14/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 15/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
            "Epoch 16/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 17/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0039\n",
            "Epoch 18/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 19/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 20/20\n",
            "\u001b[1m3974/3974\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "\n",
            "Pelatihan model selesai.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- Tahap 4: Bangun dan Latih Model ---\n",
        "# ==============================================================================\n",
        "\n",
        "# --- OPSI 1: Arsitektur 1-Lapis ---\n",
        "# print(\"--- Membangun Model LSTM 1-Lapis ---\")\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "# model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# --- OPSI 2: Arsitektur 2-Lapis (Stacked LSTM) ---\n",
        "# Hapus tanda komentar di bawah ini jika ingin menggunakan model 2-lapis\n",
        "print(\"--- Membangun Model LSTM 2-Lapis ---\")\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "\n",
        "# --- Kompilasi dan Latih Model ---\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nMemulai pelatihan model...\")\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1, verbose=1)\n",
        "print(\"\\nPelatihan model selesai.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f12377",
      "metadata": {
        "id": "01f12377"
      },
      "source": [
        "### Tahap 5: Prediksi, Evaluasi, & Simpan Hasil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67728454",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67728454",
        "outputId": "29c6e7ad-7bd8-4bec-b169-b9a325fbd14d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Membuat prediksi pada data uji...\n",
            "\u001b[1m1486/1486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "\n",
            "--- Evaluasi Final Model LSTM ---\n",
            "Mean Absolute Error (MAE):       2.3404\n",
            "Root Mean Squared Error (RMSE):  5.4088\n",
            "R-squared (R²):                  0.9601\n",
            "Symmetric MAPE (sMAPE):          21.05%\n",
            "\n",
            "DataFrame hasil berhasil disimpan ke:\n",
            "/content/drive/Othercomputers/My Laptop (2)/Git/TA_SpatioTemporal/Data/predictions/lstm_2_layer_20_epochs_results.parquet\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- Tahap 5: Prediksi, Evaluasi, dan Penyimpanan Hasil ---\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Lakukan Prediksi ---\n",
        "print(\"Membuat prediksi pada data uji...\")\n",
        "predictions_scaled = model.predict(X_test)\n",
        "\n",
        "# --- Buat DataFrame Hasil yang Solid ---\n",
        "df_hasil = test_df.loc[test_indices].copy()\n",
        "y_pred_inversed = np.array([])\n",
        "\n",
        "# --- Lakukan inverse transform per gedung ---\n",
        "for meter_id, group in df_hasil.groupby('meter_id'):\n",
        "    if meter_id in scalers:\n",
        "        group_indices = group.index\n",
        "        posisi = [test_indices.index(i) for i in group_indices]\n",
        "        preds_scaled_group = predictions_scaled[posisi]\n",
        "        dummy_pred = np.zeros((len(preds_scaled_group), len(FEATURES) + 1)); dummy_pred[:, -1] = preds_scaled_group.ravel()\n",
        "        inversed_preds = scalers[meter_id].inverse_transform(dummy_pred)[:, -1]\n",
        "        y_pred_inversed = np.append(y_pred_inversed, inversed_preds)\n",
        "\n",
        "# --- Tambahkan kolom hasil ke DataFrame ---\n",
        "df_hasil['prediksi_lstm'] = y_pred_inversed\n",
        "df_hasil.rename(columns={TARGET: 'target_aktual'}, inplace=True)\n",
        "\n",
        "# --- Evaluasi Akhir ---\n",
        "y_true = df_hasil['target_aktual']\n",
        "y_pred = df_hasil['prediksi_lstm']\n",
        "\n",
        "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)) * 100\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n--- Evaluasi Final Model LSTM ---\")\n",
        "print(f\"Mean Absolute Error (MAE):       {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE):  {rmse:.4f}\")\n",
        "print(f\"R-squared (R²):                  {r2:.4f}\")\n",
        "print(f\"Symmetric MAPE (sMAPE):          {smape:.2f}%\")\n",
        "\n",
        "# --- Simpan Hasil ---\n",
        "# Ubah nama file sesuai dengan model yang Anda latih\n",
        "output_filename = 'lstm_2_layer_20_epochs_results.parquet'\n",
        "df_hasil[['timestamp', 'meter_id', 'target_aktual', 'prediksi_lstm']].to_parquet(\n",
        "    os.path.join(PATH_PREDICTIONS, output_filename), index=False\n",
        ")\n",
        "print(f\"\\nDataFrame hasil berhasil disimpan ke:\\n{os.path.join(PATH_PREDICTIONS, output_filename)}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
